{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70bfff05",
   "metadata": {},
   "source": [
    "# 1. Business Understanding\n",
    "**Objective:** Develop a robust machine learning model that can accurately classify handwritten digits (0-9), despite variations in handwriting styles.\n",
    "\n",
    "**Challenges:** High intra-class variance due to different writing styles, potential noise in images, and class imbalance.\n",
    "\n",
    "**Success Criteria:** Model performance will be evaluated based on accuracy, precision, recall, and robustness to difficult cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31826b6",
   "metadata": {},
   "source": [
    "# 2. Data Understanding\n",
    "**Dataset:** The MNIST dataset, containing 70,000 gray scale images (60,000 for training, 10,000 for testing), each sized 28x28 pixels.\n",
    "## Feature Considerations:\n",
    "- Presence of closed loops (e.g., 0, 6, 8)\n",
    "- Stroke thickness variation\n",
    "- Aspect ratios and curvatures (e.g., distinguishing 1 from 7)\n",
    "- Edge detection and texture information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5818db",
   "metadata": {},
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abb24499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset from file. Shape of Images data set: (70000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dataArrays = np.load(\"Imports/mnist_combined.npz\")\n",
    "\n",
    "dataImages = dataArrays['images']\n",
    "dataLables = dataArrays['labels']\n",
    "\n",
    "# we should have 70K images with an with and height of 28 pixels.\n",
    "print (\"loaded dataset from file. Shape of Images data set:\", dataImages.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153d8e96",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocessing Steps:\n",
    "- Normalize pixel values (0-255 → 0-1)\n",
    "- Apply data augmentation (rotation, shifting, noise addition) to improve generalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b269b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def Preprocess_image(img):\n",
    "    \"Preprocess image: Normalize, remove noise, and binarize.\"\n",
    "    img = img / 255.0  # Normalize pixel values to range [0,1] for consistency across models.\n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)  # Apply Gaussian blur to reduce small noise artifacts. (3,3): Ksize need to be tested. IMPORTANT!!! keep these numbers odd and grater than or equal to 0\n",
    "    ret, img = cv2.threshold(img, 0.5, 1.0, cv2.THRESH_BINARY)  # Convert to binary format to simplify features. [2]\n",
    "    print(ret)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33907814",
   "metadata": {},
   "source": [
    "### Explanation of above\n",
    "Each pixel in the image is not in a binary state, they are on a gray scale which value can range from 0 to 255. So we first normalize every pixel to be a value of 0 or 1, which helps clean up the images a little.\n",
    "\n",
    "The result of this can cause the image is not most likely very noisy. So a GaussianBlur is applied to \"smooths\" out the image high frequency components and acts as a low-pass filter, with the goal of preserving the edges and boundaries of the number inside the image [1]. Or to but it another way: After we have applied the GaussianBlur, the hope is that there is only one connected set of pixels that make up the number inside the image, an there should be no orphans or single islands else where.\n",
    "\n",
    "Finally, we can use Binarization [2] to simplify features extraction later by highlighting digit strokes clearly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e6cf2",
   "metadata": {},
   "source": [
    "- Use edge-detection filters (e.g., Sobel, Laplacian) to extract features\n",
    "- Principal Component Analysis (PCA) for dimensionality reduction\n",
    "- Convert images into numerical feature vectors for models that require structured input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8088b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "552459be",
   "metadata": {},
   "source": [
    "### Explanation of above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dbf8cc",
   "metadata": {},
   "source": [
    "### Running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_sample = np.random.randint(0,len(dataImages))\n",
    "image_original = dataImages[image_sample].reshape(28,28)\n",
    "\n",
    "image_processed = Preprocess_image(image_original)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image_original, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(image_processed, cmap='gray')\n",
    "plt.title(\"Processed Image\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Extracted feature vector shape:\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c5118",
   "metadata": {},
   "source": [
    "# 4. Modeling\n",
    "**Baseline Model:** Logistic Regression or k-NN for quick benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180753f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce2fb9e5",
   "metadata": {},
   "source": [
    "## ML Approaches:\n",
    "- Support Vector Machine (SVM) with HOG features\n",
    "- Random Forest or XGBoost on extracted features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6123fdb",
   "metadata": {},
   "source": [
    "# 5. Evaluation\n",
    "**Metrics:**\n",
    "- Accuracy (primary metric)\n",
    "- Confusion Matrix to analyze misclassifications\n",
    "- Precision, Recall, F1-score for class-specific performance\n",
    "- Robustness Testing:\n",
    "- Evaluate on distorted and rotated images\n",
    "- Assess performance on ambiguous samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd2e0e4",
   "metadata": {},
   "source": [
    "# 6. References\n",
    "[1]“Gaussian Blur - an overview | ScienceDirect Topics,” www.sciencedirect.com. https://www.sciencedirect.com/topics/engineering/gaussian-blur\n",
    "\n",
    "[2]“Python | Thresholding techniques using OpenCV | Set-1 (Simple Thresholding) - GeeksforGeeks,” GeeksforGeeks, May 06, 2019. https://www.geeksforgeeks.org/python-thresholding-techniques-using-opencv-set-1-simple-thresholding/\n",
    "‌\n",
    "\n",
    "[3]F. Daghero, D. J. Pagliari, and M. Poncino, “Energy-efficient deep learning inference on edge devices,” Advances in Computers, pp. 247–301, 2021, doi: https://doi.org/10.1016/bs.adcom.2020.07.002.\n",
    "‌"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
